{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7444f30-0883-4a87-8e00-c5e5591a2a26",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b85832b1-9f31-41e4-b934-cc260e5b3b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4b0953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # GPU 메모리 비우기\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# # 새로운 GPU 컨텍스트 생성\n",
    "# with torch.cuda.device(0):\n",
    "#     torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0259cfd-b37c-4716-aacf-c91d77e41480",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bb9438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12cd3e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3090'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba24aa07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9d06262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1+cu118'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99fd9bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c2d47b-e9da-47e5-9155-cce997e63481",
   "metadata": {},
   "source": [
    "## Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9f50013-6513-44fd-8e48-06dd12ec3f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'TRAIN_WINDOW_SIZE':120, # 90일치로 학습  초기는 90일이였음 \n",
    "    'PREDICT_SIZE':21, # 21일치 예측\n",
    "    'EPOCHS':23,\n",
    "    'LEARNING_RATE':1e-4,\n",
    "    'BATCH_SIZE':4096,\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44cdbe67-eda2-42ef-bc35-0a2bfd99f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d68c38e",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3b89389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('E:/LG/LG_data/train.csv').drop(columns=['ID', '제품'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bb2fd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>대분류</th>\n",
       "      <th>중분류</th>\n",
       "      <th>소분류</th>\n",
       "      <th>브랜드</th>\n",
       "      <th>2022-01-01</th>\n",
       "      <th>2022-01-02</th>\n",
       "      <th>2022-01-03</th>\n",
       "      <th>2022-01-04</th>\n",
       "      <th>2022-01-05</th>\n",
       "      <th>2022-01-06</th>\n",
       "      <th>...</th>\n",
       "      <th>2023-03-26</th>\n",
       "      <th>2023-03-27</th>\n",
       "      <th>2023-03-28</th>\n",
       "      <th>2023-03-29</th>\n",
       "      <th>2023-03-30</th>\n",
       "      <th>2023-03-31</th>\n",
       "      <th>2023-04-01</th>\n",
       "      <th>2023-04-02</th>\n",
       "      <th>2023-04-03</th>\n",
       "      <th>2023-04-04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0007</td>\n",
       "      <td>B002-C003-0038</td>\n",
       "      <td>B002-00001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-00002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 463 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              대분류             중분류             소분류         브랜드  2022-01-01  \\\n",
       "0  B002-C001-0002  B002-C002-0007  B002-C003-0038  B002-00001           0   \n",
       "1  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-00002           0   \n",
       "\n",
       "   2022-01-02  2022-01-03  2022-01-04  2022-01-05  2022-01-06  ...  \\\n",
       "0           0           0           0           0           0  ...   \n",
       "1           0           0           0           0           0  ...   \n",
       "\n",
       "   2023-03-26  2023-03-27  2023-03-28  2023-03-29  2023-03-30  2023-03-31  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           1           3           2   \n",
       "\n",
       "   2023-04-01  2023-04-02  2023-04-03  2023-04-04  \n",
       "0           0           0           0           0  \n",
       "1           0           0           2           0  \n",
       "\n",
       "[2 rows x 463 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8286c57a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fbprophet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfbprophet\u001b[39;00m \u001b[39mimport\u001b[39;00m Prophet\n\u001b[0;32m      4\u001b[0m \u001b[39m# 데이터 로드 및 정리\u001b[39;00m\n\u001b[0;32m      5\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mE:/LG/LG_data/train.csv\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# 데이터 파일 경로를 지정\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fbprophet'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fbprophet import Prophet\n",
    "\n",
    "# 데이터 로드 및 정리\n",
    "data = pd.read_csv('E:/LG/LG_data/train.csv')  # 데이터 파일 경로를 지정\n",
    "df = data[['대분류', '중분류', '소분류', '브랜드'] + data.columns[4:].tolist()]\n",
    "df_melted = df.melt(id_vars=['대분류', '중분류', '소분류', '브랜드'], var_name='ds', value_name='y')\n",
    "\n",
    "# Prophet용 데이터 프레임 생성\n",
    "df_prophet = df_melted[df_melted['y'] > 0]  # 0이 아닌 값만 선택\n",
    "df_prophet['ds'] = pd.to_datetime(df_prophet['ds'])\n",
    "\n",
    "# Prophet 모델 초기화\n",
    "model = Prophet()\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(df_prophet)\n",
    "\n",
    "# 미래 21일치 날짜 생성\n",
    "future = model.make_future_dataframe(periods=21)\n",
    "\n",
    "# 미래 21일치 판매량 예측\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# 결과 시각화\n",
    "fig = model.plot(forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d59ef76f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not find the DLL(s) 'msvcp140_1.dll'. TensorFlow requires that these DLLs be installed in a directory that is named in your %PATH% environment variable. You may install these DLLs by downloading \"Microsoft C++ Redistributable for Visual Studio 2015, 2017 and 2019\" for your platform from this URL: https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m MinMaxScaler\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m LSTM, Dense\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\__init__.py:38\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[0;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     41\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\__init__.py:36\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtraceback\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[39m# go/tf-wildcard-import\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow \u001b[39mas\u001b[39;00m _pywrap_tensorflow\n\u001b[0;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[0;32m     39\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[39m# Bring in subpackages.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:26\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplatform\u001b[39;00m \u001b[39mimport\u001b[39;00m self_check\n\u001b[0;32m     23\u001b[0m \u001b[39m# TODO(mdan): Cleanup antipattern: import for side effects.\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[39m# Perform pre-load sanity checks in order to produce a more actionable error.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m self_check\u001b[39m.\u001b[39;49mpreload_check()\n\u001b[0;32m     28\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m   \u001b[39m# This import is expected to fail if there is an explicit shared object\u001b[39;00m\n\u001b[0;32m     32\u001b[0m   \u001b[39m# dependency (with_framework_lib=true), since we do not need RTLD_GLOBAL.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py:50\u001b[0m, in \u001b[0;36mpreload_check\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m         missing\u001b[39m.\u001b[39mappend(dll_name)\n\u001b[0;32m     49\u001b[0m     \u001b[39mif\u001b[39;00m missing:\n\u001b[1;32m---> 50\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m     51\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mCould not find the DLL(s) \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m. TensorFlow requires that these DLLs \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     52\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mbe installed in a directory that is named in your \u001b[39m\u001b[39m%%\u001b[39;00m\u001b[39mPATH\u001b[39m\u001b[39m%%\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39menvironment variable. You may install these DLLs by downloading \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m           \u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMicrosoft C++ Redistributable for Visual Studio 2015, 2017 and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     55\u001b[0m           \u001b[39m'\u001b[39m\u001b[39m2019\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m for your platform from this URL: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     56\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mhttps://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     57\u001b[0m           \u001b[39m%\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m or \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(missing))\n\u001b[0;32m     58\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m   \u001b[39m# Load a library that performs CPU feature guard checking.  Doing this here\u001b[39;00m\n\u001b[0;32m     60\u001b[0m   \u001b[39m# as a preload check makes it more likely that we detect any CPU feature\u001b[39;00m\n\u001b[0;32m     61\u001b[0m   \u001b[39m# incompatibilities before we trigger them (which would typically result in\u001b[39;00m\n\u001b[0;32m     62\u001b[0m   \u001b[39m# SIGILL).\u001b[39;00m\n\u001b[0;32m     63\u001b[0m   \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplatform\u001b[39;00m \u001b[39mimport\u001b[39;00m _pywrap_cpu_feature_guard\n",
      "\u001b[1;31mImportError\u001b[0m: Could not find the DLL(s) 'msvcp140_1.dll'. TensorFlow requires that these DLLs be installed in a directory that is named in your %PATH% environment variable. You may install these DLLs by downloading \"Microsoft C++ Redistributable for Visual Studio 2015, 2017 and 2019\" for your platform from this URL: https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "data = pd.read_csv('E:/LG/LG_data/train.csv')\n",
    "df = data[['대분류', '중분류', '소분류', '브랜드'] + data.columns[4:].tolist()]\n",
    "\n",
    "# 판매량 데이터만 추출\n",
    "sales_data = df.melt(id_vars=['대분류', '중분류', '소분류', '브랜드'], var_name='날짜', value_name='판매량')\n",
    "sales_data['날짜'] = pd.to_datetime(sales_data['날짜'])\n",
    "\n",
    "# Pivot 테이블 생성\n",
    "pivot_table = sales_data.pivot_table(index=['대분류', '중분류', '소분류', '브랜드'], columns='날짜', values='판매량').reset_index()\n",
    "\n",
    "# NaN 값을 0으로 대체\n",
    "pivot_table = pivot_table.fillna(0)\n",
    "\n",
    "# LSTM 입력 데이터 생성\n",
    "X = pivot_table.values[:, 4:-21]\n",
    "y = pivot_table.values[:, -21:]\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y_scaled = scaler.fit_transform(y)\n",
    "\n",
    "# LSTM 모델 구축\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(X_scaled.shape[1], X_scaled.shape[2])))\n",
    "model.add(Dense(21))  # 21일치 예측\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_scaled, y_scaled, epochs=50, batch_size=16, verbose=2)\n",
    "\n",
    "# 미래 21일치 판매량 예측\n",
    "future_X = X_scaled[:, -21:]  # 가장 최근 21일치 데이터를 사용\n",
    "future_X = np.reshape(future_X, (future_X.shape[0], 1, future_X.shape[1]))\n",
    "future_predictions_scaled = model.predict(future_X)\n",
    "\n",
    "# 결과 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.arange(1, 22), scaler.inverse_transform(future_predictions_scaled[0]), label='Predicted')\n",
    "plt.title('Future Sales Prediction')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Sales')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4345d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "\n",
    "\n",
    "CFG = {\n",
    "    'TRAIN_WINDOW_SIZE':120, # 90일치로 학습  초기는 90일이였음 \n",
    "    'PREDICT_SIZE':21, # 21일치 예측\n",
    "    'EPOCHS':30,\n",
    "    'LEARNING_RATE':1e-4,\n",
    "    'BATCH_SIZE':4096,\n",
    "    'SEED':41\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정\n",
    "\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('E:/LG/LG_data/train.csv').drop(columns=['ID', '제품'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 더 작은 값을 추가하여 분모가 0인 경우 방지하는 상수 정의\n",
    "EPSILON = 1e-8\n",
    "\n",
    "numeric_cols = train_data.columns[4:]\n",
    "\n",
    "# 칵 column의 min 및 max 계산\n",
    "min_values = train_data[numeric_cols].min(axis=1)\n",
    "max_values = train_data[numeric_cols].max(axis=1)\n",
    "\n",
    "# 각 행의 범위(max-min)를 계산하고, 범위가 0인 경우 EPSILON 더해주기\n",
    "ranges = max_values - min_values + EPSILON\n",
    "\n",
    "# min-max scaling 수행\n",
    "scaled_data = (train_data[numeric_cols].subtract(min_values, axis=0)).div(ranges, axis=0)\n",
    "\n",
    "# 스케일링된 데이터로 업데이트\n",
    "train_data[numeric_cols] = scaled_data\n",
    "\n",
    "# max와 min 값을 dictionary 형태로 저장\n",
    "scale_min_dict = min_values.to_dict()\n",
    "scale_max_dict = max_values.to_dict()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = ['대분류', '중분류', '소분류', '브랜드']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    label_encoder.fit(train_data[col])\n",
    "    train_data[col] = label_encoder.transform(train_data[col])\n",
    "\n",
    "\n",
    "def make_train_data(data, train_size=CFG['TRAIN_WINDOW_SIZE'], predict_size=CFG['PREDICT_SIZE']):\n",
    "    '''\n",
    "    학습 기간 블럭, 예측 기간 블럭의 세트로 데이터를 생성\n",
    "    data : 일별 판매량\n",
    "    train_size : 학습에 활용할 기간\n",
    "    predict_size : 추론할 기간\n",
    "    '''\n",
    "    num_rows = len(data)\n",
    "    window_size = train_size + predict_size\n",
    "    \n",
    "    input_data = np.empty((num_rows * (len(data.columns) - window_size + 1), train_size, len(data.iloc[0, :4]) + 1))\n",
    "    target_data = np.empty((num_rows * (len(data.columns) - window_size + 1), predict_size))\n",
    "    \n",
    "    for i in tqdm(range(num_rows)):\n",
    "        encode_info = np.array(data.iloc[i, :4])\n",
    "        sales_data = np.array(data.iloc[i, 4:])\n",
    "        \n",
    "        for j in range(len(sales_data) - window_size + 1):\n",
    "            window = sales_data[j : j + window_size]\n",
    "            temp_data = np.column_stack((np.tile(encode_info, (train_size, 1)), window[:train_size]))\n",
    "            input_data[i * (len(data.columns) - window_size + 1) + j] = temp_data\n",
    "            target_data[i * (len(data.columns) - window_size + 1) + j] = window[train_size:]\n",
    "    \n",
    "    return input_data, target_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_predict_data(data, train_size=CFG['TRAIN_WINDOW_SIZE']):\n",
    "    '''\n",
    "    평가 데이터(Test Dataset)를 추론하기 위한 Input 데이터를 생성\n",
    "    data : 일별 판매량\n",
    "    train_size : 추론을 위해 필요한 일별 판매량 기간 (= 학습에 활용할 기간)\n",
    "    '''\n",
    "    num_rows = len(data)\n",
    "    \n",
    "    input_data = np.empty((num_rows, train_size, len(data.iloc[0, :4]) + 1))\n",
    "    \n",
    "    for i in tqdm(range(num_rows)):\n",
    "        encode_info = np.array(data.iloc[i, :4])\n",
    "        sales_data = np.array(data.iloc[i, -train_size:])\n",
    "        \n",
    "        window = sales_data[-train_size : ]\n",
    "        temp_data = np.column_stack((np.tile(encode_info, (train_size, 1)), window[:train_size]))\n",
    "        input_data[i] = temp_data\n",
    "    \n",
    "    return input_data\n",
    "\n",
    "\n",
    "train_input, train_target = make_train_data(train_data)\n",
    "test_input = make_predict_data(train_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_len = len(train_input)\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "val_len = int(data_len * val_ratio)\n",
    "test_len = int(data_len * test_ratio)\n",
    "\n",
    "val_input = train_input[-val_len:]\n",
    "val_target = train_target[-val_len:]\n",
    "\n",
    "train_input = train_input[:-val_len - test_len]\n",
    "train_target = train_target[:-val_len - test_len]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_input.shape, train_target.shape, val_input.shape, val_target.shape, test_input.shape\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.Y is not None:\n",
    "            return torch.Tensor(self.X[index]), torch.Tensor(self.Y[index])\n",
    "        return torch.Tensor(self.X[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset(train_input, train_target)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = CustomDataset(val_input, val_target)\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "class ImprovedModel(nn.Module):\n",
    "    def __init__(self, input_size=5, hidden_size=512, num_layers=2, output_size=CFG['PREDICT_SIZE'], dropout_prob=0.2):\n",
    "        super(ImprovedModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.ln = nn.LayerNorm(hidden_size)  # Layer Normalization\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size // 2, output_size)\n",
    "        )\n",
    "        self.actv = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        hidden = self.init_hidden(batch_size, x.device)\n",
    "\n",
    "        gru_out, hidden = self.gru(x, hidden)\n",
    "        gru_out = self.dropout(gru_out)\n",
    "        gru_out = self.ln(gru_out)  # Applying Layer Normalization\n",
    "\n",
    "        last_output = gru_out[:, -1, :]\n",
    "\n",
    "        output = self.actv(self.fc(last_output))\n",
    "\n",
    "        return output.squeeze(1)\n",
    "    def init_hidden(self, batch_size, device):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device)\n",
    "\n",
    "def train(model, optimizer, train_loader, val_loader, device, scheduler= None):\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    best_loss = 9999999\n",
    "    best_model = None\n",
    "    \n",
    "    \n",
    "    \n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        train_mae = []\n",
    "        \n",
    "        for X, Y in tqdm(iter(train_loader)):\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(X)\n",
    "            loss = criterion(output, Y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "        \n",
    "        val_loss = validation(model, val_loader, criterion, device)\n",
    "        print(f'Epoch : [{epoch}] Train Loss : [{np.mean(train_loss):.5f}] Val Loss : [{val_loss:.5f}]')\n",
    "        \n",
    "\n",
    "        # # 학습 루프 안에서\n",
    "        # if best_loss > val_loss:\n",
    "        #     best_loss = val_loss\n",
    "        #     best_model = model\n",
    "        #     print('Model Saved')\n",
    "\n",
    "        # 학습이 끝난 후\n",
    "    return model  # 모든 모델을 반환\n",
    "\n",
    "\n",
    "def validation(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, Y in tqdm(iter(val_loader)):\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            \n",
    "            output = model(X)\n",
    "            loss = criterion(output, Y)\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "    return np.mean(val_loss)\n",
    "\n",
    "model = ImprovedModel() # BaseModel() \n",
    "optimizer = torch.optim.RAdam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "\n",
    "\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44ac8608",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15890/15890 [02:10<00:00, 122.03it/s]\n",
      "100%|██████████| 15890/15890 [00:03<00:00, 4163.13it/s]\n",
      "100%|██████████| 1238/1238 [11:26<00:00,  1.80it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 227\u001b[0m\n\u001b[0;32m    224\u001b[0m     trained_model \u001b[39m=\u001b[39m train_model(model, optimizer, train_loader, val_loader, device)\n\u001b[0;32m    226\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 227\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[25], line 224\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    216\u001b[0m model \u001b[39m=\u001b[39m ImprovedModel(\n\u001b[0;32m    217\u001b[0m     input_size\u001b[39m=\u001b[39mtrain_input\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m],  \u001b[39m# Define input_size based on your data\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     hidden_size\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m,                  \u001b[39m# Define hidden_size\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    221\u001b[0m     dropout_prob\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m                  \u001b[39m# Define dropout_prob\u001b[39;00m\n\u001b[0;32m    222\u001b[0m )\n\u001b[0;32m    223\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mRAdam(params\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mCFG[\u001b[39m\"\u001b[39m\u001b[39mLEARNING_RATE\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m--> 224\u001b[0m trained_model \u001b[39m=\u001b[39m train_model(model, optimizer, train_loader, val_loader, device)\n",
      "Cell \u001b[1;32mIn[25], line 175\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, optimizer, train_loader, val_loader, device)\u001b[0m\n\u001b[0;32m    171\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m    173\u001b[0m     train_loss\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n\u001b[1;32m--> 175\u001b[0m val_loss \u001b[39m=\u001b[39m validate_model(model, val_loader, criterion, device)\n\u001b[0;32m    176\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch [\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mCFG[\u001b[39m\"\u001b[39m\u001b[39mEPOCHS\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m] - Train Loss: \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mmean(train_loss)\u001b[39m:\u001b[39;00m\u001b[39m.5f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m - Val Loss: \u001b[39m\u001b[39m{\u001b[39;00mval_loss\u001b[39m:\u001b[39;00m\u001b[39m.5f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    178\u001b[0m \u001b[39m# # Save the best model\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[39m# if val_loss < best_loss:\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[39m#     best_loss = val_loss\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[39m#     best_model = model.state_dict()\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[39m#     print('Best model updated')\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[25], line 192\u001b[0m, in \u001b[0;36mvalidate_model\u001b[1;34m(model, val_loader, criterion, device)\u001b[0m\n\u001b[0;32m    189\u001b[0m val_loss \u001b[39m=\u001b[39m []\n\u001b[0;32m    191\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 192\u001b[0m     \u001b[39mfor\u001b[39;00m X, Y \u001b[39min\u001b[39;00m tqdm(val_loader):\n\u001b[0;32m    193\u001b[0m         X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m    194\u001b[0m         Y \u001b[39m=\u001b[39m Y\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "CFG = {\n",
    "    'TRAIN_WINDOW_SIZE': 120,\n",
    "    'PREDICT_SIZE': 21,\n",
    "    'EPOCHS': 30,\n",
    "    'LEARNING_RATE': 1e-4,\n",
    "    'BATCH_SIZE': 4096,\n",
    "    'SEED': 41\n",
    "}\n",
    "\n",
    "# Seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED'])\n",
    "\n",
    "# Load and preprocess data\n",
    "train_data = pd.read_csv('E:/LG/LG_data/train.csv').drop(columns=['ID', '제품'])\n",
    "\n",
    "# Data preprocessing function\n",
    "def preprocess_data(data):\n",
    "    EPSILON = 1e-8\n",
    "    numeric_cols = data.columns[4:]\n",
    "    \n",
    "    min_values = data[numeric_cols].min(axis=1)\n",
    "    max_values = data[numeric_cols].max(axis=1)\n",
    "    ranges = max_values - min_values + EPSILON\n",
    "    \n",
    "    scaled_data = (data[numeric_cols].subtract(min_values, axis=0)).div(ranges, axis=0)\n",
    "    \n",
    "    scale_min_dict = min_values.to_dict()\n",
    "    scale_max_dict = max_values.to_dict()\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    categorical_columns = ['대분류', '중분류', '소분류', '브랜드']\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        label_encoder.fit(data[col])\n",
    "        data[col] = label_encoder.transform(data[col])\n",
    "    \n",
    "    return scaled_data, scale_min_dict, scale_max_dict\n",
    "\n",
    "scaled_data, scale_min_dict, scale_max_dict = preprocess_data(train_data)\n",
    "\n",
    "# Define custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.Y is not None:\n",
    "            return torch.Tensor(self.X[index]), torch.Tensor(self.Y[index])\n",
    "        return torch.Tensor(self.X[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "# Model class\n",
    "class ImprovedModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_prob):\n",
    "        super(ImprovedModel, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.ln = nn.LayerNorm(hidden_size)  # Layer Normalization\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size // 2, output_size)\n",
    "        )\n",
    "        self.actv = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        hidden = self.init_hidden(batch_size, x.device)\n",
    "\n",
    "        gru_out, hidden = self.gru(x, hidden)\n",
    "        gru_out = self.dropout(gru_out)\n",
    "        gru_out = self.ln(gru_out)  # Applying Layer Normalization\n",
    "\n",
    "        last_output = gru_out[:, -1, :]\n",
    "\n",
    "        output = self.actv(self.fc(last_output))\n",
    "\n",
    "        return output.squeeze(1)\n",
    "    \n",
    "    def init_hidden(self, batch_size, device):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device)\n",
    "\n",
    "# Define the make_train_data and make_predict_data functions\n",
    "def make_train_data(data, train_size=CFG['TRAIN_WINDOW_SIZE'], predict_size=CFG['PREDICT_SIZE']):\n",
    "    num_rows = len(data)\n",
    "    window_size = train_size + predict_size\n",
    "\n",
    "    input_data = np.empty((num_rows * (len(data.columns) - window_size + 1), train_size, len(data.iloc[0, :4]) + 1))\n",
    "    target_data = np.empty((num_rows * (len(data.columns) - window_size + 1), predict_size))\n",
    "\n",
    "    for i in tqdm(range(num_rows)):\n",
    "        encode_info = np.array(data.iloc[i, :4])\n",
    "        sales_data = np.array(data.iloc[i, 4:])\n",
    "\n",
    "        for j in range(len(sales_data) - window_size + 1):\n",
    "            window = sales_data[j : j + window_size]\n",
    "            temp_data = np.column_stack((np.tile(encode_info, (train_size, 1)), window[:train_size]))\n",
    "            input_data[i * (len(data.columns) - window_size + 1) + j] = temp_data\n",
    "            target_data[i * (len(data.columns) - window_size + 1) + j] = window[train_size:]\n",
    "\n",
    "    return input_data, target_data\n",
    "\n",
    "def make_predict_data(data, train_size=CFG['TRAIN_WINDOW_SIZE']):\n",
    "    num_rows = len(data)\n",
    "\n",
    "    input_data = np.empty((num_rows, train_size, len(data.iloc[0, :4]) + 1))\n",
    "\n",
    "    for i in tqdm(range(num_rows)):\n",
    "        encode_info = np.array(data.iloc[i, :4])\n",
    "        sales_data = np.array(data.iloc[i, -train_size:])\n",
    "\n",
    "        window = sales_data[-train_size:]\n",
    "        temp_data = np.column_stack((np.tile(encode_info, (train_size, 1)), window[:train_size]))\n",
    "        input_data[i] = temp_data\n",
    "\n",
    "    return input_data\n",
    "\n",
    "# Training function\n",
    "def train_model(model, optimizer, train_loader, val_loader, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    best_loss = float('inf')\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(1, CFG['EPOCHS'] + 1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        \n",
    "        for X, Y in tqdm(train_loader):\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(X)\n",
    "            loss = criterion(output, Y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "        \n",
    "        val_loss = validate_model(model, val_loader, criterion, device)\n",
    "        print(f'Epoch [{epoch}/{CFG[\"EPOCHS\"]}] - Train Loss: {np.mean(train_loss):.5f} - Val Loss: {val_loss:.5f}')\n",
    "        \n",
    "        # # Save the best model\n",
    "        # if val_loss < best_loss:\n",
    "        #     best_loss = val_loss\n",
    "        #     best_model = model.state_dict()\n",
    "        #     print('Best model updated')\n",
    "\n",
    "    return model\n",
    "\n",
    "# Validation function\n",
    "def validate_model(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, Y in tqdm(val_loader):\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "\n",
    "            output = model(X)\n",
    "            loss = criterion(output, Y)\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "    return np.mean(val_loss)\n",
    "\n",
    "def main():\n",
    "    # Create train and validation datasets...\n",
    "    train_input, train_target = make_train_data(scaled_data)\n",
    "    val_input = make_predict_data(scaled_data)\n",
    "\n",
    "    train_dataset = CustomDataset(train_input, train_target)\n",
    "    val_dataset = CustomDataset(val_input, None)  # Target is None for prediction\n",
    "\n",
    "    # Create data loaders...\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "    # Initialize and train model...\n",
    "    model = ImprovedModel(\n",
    "        input_size=train_input.shape[2],  # Define input_size based on your data\n",
    "        hidden_size=512,                  # Define hidden_size\n",
    "        num_layers=2,                     # Define num_layers\n",
    "        output_size=CFG['PREDICT_SIZE'],\n",
    "        dropout_prob=0.2                  # Define dropout_prob\n",
    "    )\n",
    "    optimizer = torch.optim.RAdam(params=model.parameters(), lr=CFG[\"LEARNING_RATE\"])\n",
    "    trained_model = train_model(model, optimizer, train_loader, val_loader, device)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a2e9e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f0ee8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6100eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbff5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86b51dc8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Per-column arrays must each be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m df \u001b[39m=\u001b[39m data[[\u001b[39m'\u001b[39m\u001b[39m대분류\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m중분류\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m소분류\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m브랜드\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m data\u001b[39m.\u001b[39mcolumns[\u001b[39m4\u001b[39m:]\u001b[39m.\u001b[39mtolist()]\n\u001b[0;32m     12\u001b[0m \u001b[39m# 판매량 데이터만 추출\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m sales_data \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mmelt(id_vars\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39m대분류\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m중분류\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m소분류\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m브랜드\u001b[39;49m\u001b[39m'\u001b[39;49m], var_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m날짜\u001b[39;49m\u001b[39m'\u001b[39;49m, value_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m판매량\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     14\u001b[0m sales_data[\u001b[39m'\u001b[39m\u001b[39m날짜\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(sales_data[\u001b[39m'\u001b[39m\u001b[39m날짜\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     16\u001b[0m \u001b[39m# Pivot 테이블 생성\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:8975\u001b[0m, in \u001b[0;36mDataFrame.melt\u001b[1;34m(self, id_vars, value_vars, var_name, value_name, col_level, ignore_index)\u001b[0m\n\u001b[0;32m   8965\u001b[0m \u001b[39m@Appender\u001b[39m(_shared_docs[\u001b[39m\"\u001b[39m\u001b[39mmelt\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m%\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mcaller\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mdf.melt(\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mother\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mmelt\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[0;32m   8966\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmelt\u001b[39m(\n\u001b[0;32m   8967\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   8973\u001b[0m     ignore_index: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   8974\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m-> 8975\u001b[0m     \u001b[39mreturn\u001b[39;00m melt(\n\u001b[0;32m   8976\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   8977\u001b[0m         id_vars\u001b[39m=\u001b[39;49mid_vars,\n\u001b[0;32m   8978\u001b[0m         value_vars\u001b[39m=\u001b[39;49mvalue_vars,\n\u001b[0;32m   8979\u001b[0m         var_name\u001b[39m=\u001b[39;49mvar_name,\n\u001b[0;32m   8980\u001b[0m         value_name\u001b[39m=\u001b[39;49mvalue_name,\n\u001b[0;32m   8981\u001b[0m         col_level\u001b[39m=\u001b[39;49mcol_level,\n\u001b[0;32m   8982\u001b[0m         ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[0;32m   8983\u001b[0m     )\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmelt\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\melt.py:153\u001b[0m, in \u001b[0;36mmelt\u001b[1;34m(frame, id_vars, value_vars, var_name, value_name, col_level, ignore_index)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[39mfor\u001b[39;00m i, col \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(var_name):\n\u001b[0;32m    150\u001b[0m     \u001b[39m# asanyarray will keep the columns as an Index\u001b[39;00m\n\u001b[0;32m    151\u001b[0m     mdata[col] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(frame\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39m_get_level_values(i))\u001b[39m.\u001b[39mrepeat(N)\n\u001b[1;32m--> 153\u001b[0m result \u001b[39m=\u001b[39m frame\u001b[39m.\u001b[39;49m_constructor(mdata, columns\u001b[39m=\u001b[39;49mmcolumns)\n\u001b[0;32m    155\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_index:\n\u001b[0;32m    156\u001b[0m     result\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m tile_compat(frame\u001b[39m.\u001b[39mindex, K)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    703\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    704\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    705\u001b[0m     )\n\u001b[0;32m    707\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    708\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 709\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    710\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    711\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m \u001b[39mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:436\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    432\u001b[0m missing \u001b[39m=\u001b[39m arrays\u001b[39m.\u001b[39misna()\n\u001b[0;32m    433\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    434\u001b[0m     \u001b[39m# GH10856\u001b[39;00m\n\u001b[0;32m    435\u001b[0m     \u001b[39m# raise ValueError if only scalars in dict\u001b[39;00m\n\u001b[1;32m--> 436\u001b[0m     index \u001b[39m=\u001b[39m _extract_index(arrays[\u001b[39m~\u001b[39;49mmissing])\n\u001b[0;32m    437\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m     index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:642\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    640\u001b[0m         raw_lengths\u001b[39m.\u001b[39mappend(\u001b[39mlen\u001b[39m(val))\n\u001b[0;32m    641\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(val, np\u001b[39m.\u001b[39mndarray) \u001b[39mand\u001b[39;00m val\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 642\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    644\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m indexes \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m raw_lengths:\n\u001b[0;32m    645\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIf using all scalar values, you must pass an index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Per-column arrays must each be 1-dimensional"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "data = pd.read_csv('E:/LG/LG_data/train.csv')\n",
    "df = data[['대분류', '중분류', '소분류', '브랜드'] + data.columns[4:].tolist()]\n",
    "\n",
    "# 판매량 데이터만 추출\n",
    "sales_data = df.melt(id_vars=['대분류', '중분류', '소분류', '브랜드'], var_name='날짜', value_name='판매량')\n",
    "sales_data['날짜'] = pd.to_datetime(sales_data['날짜'])\n",
    "\n",
    "# Pivot 테이블 생성\n",
    "pivot_table = sales_data.pivot_table(index=['대분류', '중분류', '소분류', '브랜드'], columns='날짜', values='판매량').reset_index()\n",
    "\n",
    "# NaN 값을 0으로 대체\n",
    "pivot_table = pivot_table.fillna(0)\n",
    "\n",
    "\n",
    "# LSTM 입력 데이터 생성\n",
    "X = pivot_table.pivot_table(index=['대분류', '중분류', '소분류', '브랜드'], columns='날짜', values='판매량').fillna(0).values[:, :-21]\n",
    "y = pivot_table.pivot_table(index=['대분류', '중분류', '소분류', '브랜드'], columns='날짜', values='판매량').fillna(0).values[:, -21:]\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y_scaled = scaler.fit_transform(y)\n",
    "\n",
    "# PyTorch를 위한 텐서로 변환\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_scaled, dtype=torch.float32)\n",
    "\n",
    "# LSTM 모델 구축\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])  # 마지막 시점의 출력만 사용\n",
    "        return out\n",
    "\n",
    "input_size = X_tensor.shape[1]\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "output_size = 21  # 21일치 예측\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "# 손실 함수와 최적화 알고리즘 설정\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 모델 학습\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(X_tensor.unsqueeze(0))  # 배치 차원 추가\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs, y_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# # 미래 21일치 판매량 예측\n",
    "# future_X = X_scaled[:, -21:]\n",
    "# future_X_tensor = torch.tensor(future_X, dtype=torch.float32)\n",
    "# future_X_tensor = future_X_tensor.unsqueeze(0)  # 배치 차원 추가\n",
    "# future_predictions_scaled = model(future_X_tensor).detach().numpy()\n",
    "\n",
    "# # 결과 시각화\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(np.arange(1, 22), scaler.inverse_transform(future_predictions_scaled)[0], label='Predicted')\n",
    "# plt.title('Future Sales Prediction')\n",
    "# plt.xlabel('Days')\n",
    "# plt.ylabel('Sales')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ba3185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83ed720c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    대분류             중분류             소분류         브랜드  \\\n",
      "7293505  B002-C001-0003  B002-C002-0008  B002-C003-0042  B002-03799   \n",
      "7293506  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03799   \n",
      "7293507  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03799   \n",
      "7293508  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03799   \n",
      "7293509  B002-C001-0002  B002-C002-0004  B002-C003-0020  B002-03799   \n",
      "\n",
      "                날짜  판매량  \n",
      "7293505 2023-04-04    0  \n",
      "7293506 2023-04-04    3  \n",
      "7293507 2023-04-04    0  \n",
      "7293508 2023-04-04    2  \n",
      "7293509 2023-04-04    0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "train_data = pd.read_csv('E:/LG/LG_data/train.csv').drop(columns=['ID', '제품'])\n",
    "\n",
    "\n",
    "# '날짜' 열을 행으로 변환\n",
    "df_melted = pd.melt(train_data, id_vars=['대분류', '중분류', '소분류', '브랜드'], var_name='날짜', value_name='판매량')\n",
    "\n",
    "# '날짜' 열의 데이터를 날짜형으로 변환\n",
    "df_melted['날짜'] = pd.to_datetime(df_melted['날짜'])\n",
    "\n",
    "# 결과 출력\n",
    "print(df_melted.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "9d277a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                브랜드         날짜      검색수\n",
      "1455025  B002-03794 2022-04-02  1.78416\n",
      "1455026  B002-03795 2022-04-02  0.00000\n",
      "1455027  B002-03796 2022-04-02  0.07252\n",
      "1455028  B002-03798 2022-04-02  0.10153\n",
      "1455029  B002-03799 2022-04-02  5.07687\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "csv_file_path = 'E:/LG/LG_data/brand_keyword_cnt.csv'\n",
    "df_loaded = pd.read_csv(csv_file_path)\n",
    "\n",
    "# '날짜' 열을 행으로 변환 (melt 사용)\n",
    "df_melteds = pd.melt(df_loaded, id_vars=['브랜드'], var_name='날짜', value_name='검색수')\n",
    "\n",
    "# '날짜' 열의 데이터를 날짜형으로 변환\n",
    "df_melteds['날짜'] = pd.to_datetime(df_melted['날짜'])\n",
    "\n",
    "# 결과 출력\n",
    "print(df_melteds.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "12f21775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               대분류             중분류             소분류         브랜드         날짜  \\\n",
      "32  B002-C001-0002  B002-C002-0007  B002-C003-0036  B002-00010 2022-01-01   \n",
      "34  B002-C001-0002  B002-C002-0007  B002-C003-0036  B002-00012 2022-01-01   \n",
      "35  B002-C001-0002  B002-C002-0005  B002-C003-0025  B002-00013 2022-01-01   \n",
      "36  B002-C001-0002  B002-C002-0005  B002-C003-0025  B002-00013 2022-01-01   \n",
      "40  B002-C001-0001  B002-C002-0001  B002-C003-0003  B002-00017 2022-01-01   \n",
      "\n",
      "    판매량       검색수  \n",
      "32    2  0.333620  \n",
      "34    2  0.362630  \n",
      "35   10  2.901070  \n",
      "36   10  2.901070  \n",
      "40    6  0.115993  \n",
      "데이터가 E:/LG/LG_data/filtered_merged_data.csv에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 첫 번째 CSV 파일 불러오기\n",
    "csv_file_path1 = 'E:/LG/LG_data/train.csv'\n",
    "train_data = pd.read_csv(csv_file_path1).drop(columns=['ID', '제품'])\n",
    "\n",
    "# '날짜' 열을 행으로 변환\n",
    "df_melted = pd.melt(train_data, id_vars=['대분류', '중분류', '소분류', '브랜드'], var_name='날짜', value_name='판매량')\n",
    "\n",
    "# '날짜' 열의 데이터를 날짜형으로 변환\n",
    "df_melted['날짜'] = pd.to_datetime(df_melted['날짜'])\n",
    "\n",
    "# 두 번째 CSV 파일 불러오기\n",
    "csv_file_path2 = 'E:/LG/LG_data/brand_keyword_cnt.csv'\n",
    "df_loaded = pd.read_csv(csv_file_path2)\n",
    "\n",
    "# '날짜' 열을 행으로 변환 (melt 사용)\n",
    "df_melteds = pd.melt(df_loaded, id_vars=['브랜드'], var_name='날짜', value_name='검색수')\n",
    "\n",
    "# '날짜' 열의 데이터를 날짜형으로 변환\n",
    "df_melteds['날짜'] = pd.to_datetime(df_melteds['날짜'])\n",
    "\n",
    "# 브랜드명을 기준으로 데이터프레임 병합 (merge 사용)\n",
    "result_df = df_melted.merge(df_melteds, how='left', left_on=['브랜드', '날짜'], right_on=['브랜드', '날짜'])\n",
    "\n",
    "\n",
    "# 판매량이나 검색수가 0이 아닌 데이터만 선택하여 새로운 데이터프레임 생성\n",
    "filtered_result_df = result_df[(result_df['판매량'] != 0) & (result_df['검색수'] != 0)]\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "print(filtered_result_df.head())\n",
    "\n",
    "# 새로운 파일로 저장\n",
    "result_file_path = 'E:/LG/LG_data/filtered_merged_data.csv'\n",
    "result_df.to_csv(result_file_path, index=False)\n",
    "print(f\"데이터가 {result_file_path}에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "6f3f2bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               대분류             중분류             소분류         브랜드         날짜  \\\n",
      "32  B002-C001-0002  B002-C002-0007  B002-C003-0036  B002-00010 2022-01-01   \n",
      "34  B002-C001-0002  B002-C002-0007  B002-C003-0036  B002-00012 2022-01-01   \n",
      "35  B002-C001-0002  B002-C002-0005  B002-C003-0025  B002-00013 2022-01-01   \n",
      "36  B002-C001-0002  B002-C002-0005  B002-C003-0025  B002-00013 2022-01-01   \n",
      "40  B002-C001-0001  B002-C002-0001  B002-C003-0003  B002-00017 2022-01-01   \n",
      "\n",
      "    판매량       검색수  \n",
      "32    2  0.333620  \n",
      "34    2  0.362630  \n",
      "35   10  2.901070  \n",
      "36   10  2.901070  \n",
      "40    6  0.115993  \n",
      "데이터가 E:/LG/LG_data/filtered_merged_data.csv에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 첫 번째 CSV 파일 불러오기\n",
    "csv_file_path1 = 'E:/LG/LG_data/train.csv'\n",
    "train_data = pd.read_csv(csv_file_path1).drop(columns=['ID', '제품'])\n",
    "\n",
    "# '날짜' 열을 행으로 변환\n",
    "df_melted = pd.melt(train_data, id_vars=['대분류', '중분류', '소분류', '브랜드'], var_name='날짜', value_name='판매량')\n",
    "\n",
    "# '날짜' 열의 데이터를 날짜형으로 변환\n",
    "df_melted['날짜'] = pd.to_datetime(df_melted['날짜'])\n",
    "\n",
    "# 두 번째 CSV 파일 불러오기\n",
    "csv_file_path2 = 'E:/LG/LG_data/brand_keyword_cnt.csv'\n",
    "df_loaded = pd.read_csv(csv_file_path2)\n",
    "\n",
    "# '날짜' 열을 행으로 변환 (melt 사용)\n",
    "df_melteds = pd.melt(df_loaded, id_vars=['브랜드'], var_name='날짜', value_name='검색수')\n",
    "\n",
    "# '날짜' 열의 데이터를 날짜형으로 변환\n",
    "df_melteds['날짜'] = pd.to_datetime(df_melteds['날짜'])\n",
    "\n",
    "# 브랜드명을 기준으로 데이터프레임 병합 (merge 사용)\n",
    "result_df = df_melted.merge(df_melteds, how='left', left_on=['브랜드', '날짜'], right_on=['브랜드', '날짜'])\n",
    "\n",
    "# 판매량이나 검색수가 0이 아닌 데이터만 선택하여 새로운 데이터프레임 생성\n",
    "filtered_result_df = result_df[(result_df['판매량'] != 0) & (result_df['검색수'] != 0)]\n",
    "\n",
    "# 판매량과 검색수가 같은 경우를 제거\n",
    "filtered_result_df = filtered_result_df[filtered_result_df['판매량'] != filtered_result_df['검색수']]\n",
    "\n",
    "# 결과 출력\n",
    "print(filtered_result_df.head())\n",
    "\n",
    "# 새로운 파일로 저장\n",
    "result_file_path = 'E:/LG/LG_data/filtered_merged_data.csv'\n",
    "filtered_result_df.to_csv(result_file_path, index=False)\n",
    "print(f\"데이터가 {result_file_path}에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "d0254efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               대분류             중분류             소분류         브랜드         날짜  \\\n",
      "32  B002-C001-0002  B002-C002-0007  B002-C003-0036  B002-00010 2022-01-01   \n",
      "34  B002-C001-0002  B002-C002-0007  B002-C003-0036  B002-00012 2022-01-01   \n",
      "35  B002-C001-0002  B002-C002-0005  B002-C003-0025  B002-00013 2022-01-01   \n",
      "36  B002-C001-0002  B002-C002-0005  B002-C003-0025  B002-00013 2022-01-01   \n",
      "40  B002-C001-0001  B002-C002-0001  B002-C003-0003  B002-00017 2022-01-01   \n",
      "\n",
      "    판매량       검색수  \n",
      "32    2  0.333620  \n",
      "34    2  0.362630  \n",
      "35   10  2.901070  \n",
      "36   10  2.901070  \n",
      "40    6  0.115993  \n",
      "데이터가 E:/LG/LG_data/filtered_merged_data.csv에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 첫 번째 CSV 파일 불러오기\n",
    "csv_file_path1 = 'E:/LG/LG_data/train.csv'\n",
    "train_data = pd.read_csv(csv_file_path1).drop(columns=['ID', '제품'])\n",
    "\n",
    "# '날짜' 열을 행으로 변환\n",
    "df_melted = pd.melt(train_data, id_vars=['대분류', '중분류', '소분류', '브랜드'], var_name='날짜', value_name='판매량')\n",
    "\n",
    "# '날짜' 열의 데이터를 날짜형으로 변환\n",
    "df_melted['날짜'] = pd.to_datetime(df_melted['날짜'])\n",
    "\n",
    "# 두 번째 CSV 파일 불러오기\n",
    "csv_file_path2 = 'E:/LG/LG_data/brand_keyword_cnt.csv'\n",
    "df_loaded = pd.read_csv(csv_file_path2)\n",
    "\n",
    "# '날짜' 열을 행으로 변환 (melt 사용)\n",
    "df_melteds = pd.melt(df_loaded, id_vars=['브랜드'], var_name='날짜', value_name='검색수')\n",
    "\n",
    "# '날짜' 열의 데이터를 날짜형으로 변환\n",
    "df_melteds['날짜'] = pd.to_datetime(df_melteds['날짜'])\n",
    "\n",
    "# 브랜드명을 기준으로 데이터프레임 병합 (merge 사용)\n",
    "result_df = df_melted.merge(df_melteds, how='left', left_on=['브랜드', '날짜'], right_on=['브랜드', '날짜'])\n",
    "\n",
    "# 판매량과 검색수가 0이 아닌 경우만 선택하여 새로운 데이터프레임 생성\n",
    "filtered_result_df = result_df[(result_df['판매량'] != 0) & (result_df['검색수'] != 0)]\n",
    "\n",
    "# 판매량과 검색수가 같은 경우를 제거\n",
    "filtered_result_df = filtered_result_df[filtered_result_df['판매량'] != filtered_result_df['검색수']]\n",
    "\n",
    "# 결과 출력\n",
    "print(filtered_result_df.head())\n",
    "\n",
    "# 행 수를 15889개로 조절\n",
    "desired_row_count = 15889\n",
    "filtered_result_df = filtered_result_df[:desired_row_count]\n",
    "\n",
    "# 새로운 파일로 저장\n",
    "result_file_path = 'E:/LG/LG_data/filtered_merged_data.csv'\n",
    "result_df.to_csv(result_file_path, index=False)\n",
    "print(f\"데이터가 {result_file_path}에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "910d4ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>대분류</th>\n",
       "      <th>중분류</th>\n",
       "      <th>소분류</th>\n",
       "      <th>브랜드</th>\n",
       "      <th>날짜</th>\n",
       "      <th>판매량</th>\n",
       "      <th>검색수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7293480</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293481</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293482</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293483</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293484</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293485</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293486</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293487</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293488</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293489</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293490</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293491</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293492</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293493</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293494</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293495</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293496</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293497</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293498</th>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0009</td>\n",
       "      <td>B002-C003-0049</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293499</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>22</td>\n",
       "      <td>0.10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293500</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293501</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293502</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293503</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293504</th>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0002</td>\n",
       "      <td>B002-C003-0010</td>\n",
       "      <td>B002-03799</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>5.07687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293505</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0042</td>\n",
       "      <td>B002-03799</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>5.07687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293506</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03799</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>3</td>\n",
       "      <td>5.07687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293507</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03799</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>5.07687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293508</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03799</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>2</td>\n",
       "      <td>5.07687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293509</th>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0004</td>\n",
       "      <td>B002-C003-0020</td>\n",
       "      <td>B002-03799</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>5.07687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    대분류             중분류             소분류         브랜드  \\\n",
       "7293480  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293481  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293482  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293483  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293484  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293485  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293486  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293487  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293488  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293489  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293490  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293491  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293492  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293493  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293494  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293495  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293496  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293497  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293498  B002-C001-0002  B002-C002-0009  B002-C003-0049  B002-03798   \n",
       "7293499  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293500  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293501  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293502  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293503  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293504  B002-C001-0002  B002-C002-0002  B002-C003-0010  B002-03799   \n",
       "7293505  B002-C001-0003  B002-C002-0008  B002-C003-0042  B002-03799   \n",
       "7293506  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03799   \n",
       "7293507  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03799   \n",
       "7293508  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03799   \n",
       "7293509  B002-C001-0002  B002-C002-0004  B002-C003-0020  B002-03799   \n",
       "\n",
       "                날짜  판매량      검색수  \n",
       "7293480 2023-04-04    2  0.10153  \n",
       "7293481 2023-04-04    0  0.10153  \n",
       "7293482 2023-04-04    0  0.10153  \n",
       "7293483 2023-04-04    0  0.10153  \n",
       "7293484 2023-04-04    0  0.10153  \n",
       "7293485 2023-04-04    0  0.10153  \n",
       "7293486 2023-04-04    0  0.10153  \n",
       "7293487 2023-04-04    0  0.10153  \n",
       "7293488 2023-04-04    0  0.10153  \n",
       "7293489 2023-04-04    0  0.10153  \n",
       "7293490 2023-04-04    0  0.10153  \n",
       "7293491 2023-04-04    0  0.10153  \n",
       "7293492 2023-04-04    0  0.10153  \n",
       "7293493 2023-04-04    0  0.10153  \n",
       "7293494 2023-04-04    0  0.10153  \n",
       "7293495 2023-04-04    0  0.10153  \n",
       "7293496 2023-04-04    0  0.10153  \n",
       "7293497 2023-04-04    1  0.10153  \n",
       "7293498 2023-04-04    0  0.10153  \n",
       "7293499 2023-04-04   22  0.10153  \n",
       "7293500 2023-04-04    5  0.10153  \n",
       "7293501 2023-04-04    1  0.10153  \n",
       "7293502 2023-04-04    0  0.10153  \n",
       "7293503 2023-04-04    0  0.10153  \n",
       "7293504 2023-04-04    0  5.07687  \n",
       "7293505 2023-04-04    0  5.07687  \n",
       "7293506 2023-04-04    3  5.07687  \n",
       "7293507 2023-04-04    0  5.07687  \n",
       "7293508 2023-04-04    2  5.07687  \n",
       "7293509 2023-04-04    0  5.07687  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "670479e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>판매량</th>\n",
       "      <th>검색수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15889</td>\n",
       "      <td>15889.000000</td>\n",
       "      <td>15660.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-01-03 07:11:56.193593088</td>\n",
       "      <td>47.769526</td>\n",
       "      <td>7.140524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.072398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2022-01-02 00:00:00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.319115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-01-03 00:00:00</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.015370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2022-01-05 00:00:00</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>3.060630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2022-01-06 00:00:00</td>\n",
       "      <td>15056.000000</td>\n",
       "      <td>875.140589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>272.681637</td>\n",
       "      <td>26.574081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  날짜           판매량           검색수\n",
       "count                          15889  15889.000000  15660.000000\n",
       "mean   2022-01-03 07:11:56.193593088     47.769526      7.140524\n",
       "min              2022-01-01 00:00:00      1.000000      0.072398\n",
       "25%              2022-01-02 00:00:00      3.000000      0.319115\n",
       "50%              2022-01-03 00:00:00      7.000000      1.015370\n",
       "75%              2022-01-05 00:00:00     23.000000      3.060630\n",
       "max              2022-01-06 00:00:00  15056.000000    875.140589\n",
       "std                              NaN    272.681637     26.574081"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_result_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "db47ff88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 15889 entries, 32 to 83792\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   대분류     15889 non-null  object        \n",
      " 1   중분류     15889 non-null  object        \n",
      " 2   소분류     15889 non-null  object        \n",
      " 3   브랜드     15889 non-null  object        \n",
      " 4   날짜      15889 non-null  datetime64[ns]\n",
      " 5   판매량     15889 non-null  int64         \n",
      " 6   검색수     15660 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(4)\n",
      "memory usage: 993.1+ KB\n"
     ]
    }
   ],
   "source": [
    "filtered_result_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "5911c982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>대분류</th>\n",
       "      <th>중분류</th>\n",
       "      <th>소분류</th>\n",
       "      <th>브랜드</th>\n",
       "      <th>날짜</th>\n",
       "      <th>판매량</th>\n",
       "      <th>검색수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83781</th>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0005</td>\n",
       "      <td>B002-C003-0025</td>\n",
       "      <td>B002-01040</td>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>20</td>\n",
       "      <td>0.623730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83783</th>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0005</td>\n",
       "      <td>B002-C003-0025</td>\n",
       "      <td>B002-01040</td>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>10</td>\n",
       "      <td>0.623730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83784</th>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0005</td>\n",
       "      <td>B002-C003-0025</td>\n",
       "      <td>B002-01040</td>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>350</td>\n",
       "      <td>0.623730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83785</th>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0005</td>\n",
       "      <td>B002-C003-0025</td>\n",
       "      <td>B002-01040</td>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>350</td>\n",
       "      <td>0.623730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83792</th>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0006</td>\n",
       "      <td>B002-C003-0034</td>\n",
       "      <td>B002-01045</td>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>2</td>\n",
       "      <td>12.706759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  대분류             중분류             소분류         브랜드         날짜  \\\n",
       "83781  B002-C001-0002  B002-C002-0005  B002-C003-0025  B002-01040 2022-01-06   \n",
       "83783  B002-C001-0002  B002-C002-0005  B002-C003-0025  B002-01040 2022-01-06   \n",
       "83784  B002-C001-0002  B002-C002-0005  B002-C003-0025  B002-01040 2022-01-06   \n",
       "83785  B002-C001-0002  B002-C002-0005  B002-C003-0025  B002-01040 2022-01-06   \n",
       "83792  B002-C001-0002  B002-C002-0006  B002-C003-0034  B002-01045 2022-01-06   \n",
       "\n",
       "       판매량        검색수  \n",
       "83781   20   0.623730  \n",
       "83783   10   0.623730  \n",
       "83784  350   0.623730  \n",
       "83785  350   0.623730  \n",
       "83792    2  12.706759  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_result_df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21e80a6",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "7e2bcdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              대분류             중분류             소분류         브랜드         날짜  판매량  \\\n",
      "0  B002-C001-0002  B002-C002-0007  B002-C003-0038  B002-00001 2022-01-01  0.0   \n",
      "1  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-00002 2022-01-01  0.0   \n",
      "2  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-00002 2022-01-01  0.0   \n",
      "3  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-00002 2022-01-01  0.0   \n",
      "4  B002-C001-0001  B002-C002-0001  B002-C003-0003  B002-00003 2022-01-01  0.0   \n",
      "\n",
      "        검색수  \n",
      "0  0.000063  \n",
      "1  0.000945  \n",
      "2  0.000945  \n",
      "3  0.000945  \n",
      "4  0.000025  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 주어진 데이터의 판매량과 검색수를 Min-Max 스케일링\n",
    "result_df['판매량'] = (result_df['판매량'] - result_df['판매량'].min()) / (result_df['판매량'].max() - result_df['판매량'].min()) \n",
    "result_df['검색수'] = (result_df['검색수'] - result_df['검색수'].min()) / (result_df['검색수'].max() - result_df['검색수'].min()) \n",
    "\n",
    "print(result_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "af018284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>2023-04-05</th>\n",
       "      <th>2023-04-06</th>\n",
       "      <th>2023-04-07</th>\n",
       "      <th>2023-04-08</th>\n",
       "      <th>2023-04-09</th>\n",
       "      <th>2023-04-10</th>\n",
       "      <th>2023-04-11</th>\n",
       "      <th>2023-04-12</th>\n",
       "      <th>2023-04-13</th>\n",
       "      <th>...</th>\n",
       "      <th>2023-04-16</th>\n",
       "      <th>2023-04-17</th>\n",
       "      <th>2023-04-18</th>\n",
       "      <th>2023-04-19</th>\n",
       "      <th>2023-04-20</th>\n",
       "      <th>2023-04-21</th>\n",
       "      <th>2023-04-22</th>\n",
       "      <th>2023-04-23</th>\n",
       "      <th>2023-04-24</th>\n",
       "      <th>2023-04-25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15885</th>\n",
       "      <td>15885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15886</th>\n",
       "      <td>15886</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15887</th>\n",
       "      <td>15887</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15888</th>\n",
       "      <td>15888</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15889</th>\n",
       "      <td>15889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  2023-04-05  2023-04-06  2023-04-07  2023-04-08  2023-04-09  \\\n",
       "15885  15885           0           0           0           0           0   \n",
       "15886  15886           0           0           0           0           0   \n",
       "15887  15887           0           0           0           0           0   \n",
       "15888  15888           0           0           0           0           0   \n",
       "15889  15889           0           0           0           0           0   \n",
       "\n",
       "       2023-04-10  2023-04-11  2023-04-12  2023-04-13  ...  2023-04-16  \\\n",
       "15885           0           0           0           0  ...           0   \n",
       "15886           0           0           0           0  ...           0   \n",
       "15887           0           0           0           0  ...           0   \n",
       "15888           0           0           0           0  ...           0   \n",
       "15889           0           0           0           0  ...           0   \n",
       "\n",
       "       2023-04-17  2023-04-18  2023-04-19  2023-04-20  2023-04-21  2023-04-22  \\\n",
       "15885           0           0           0           0           0           0   \n",
       "15886           0           0           0           0           0           0   \n",
       "15887           0           0           0           0           0           0   \n",
       "15888           0           0           0           0           0           0   \n",
       "15889           0           0           0           0           0           0   \n",
       "\n",
       "       2023-04-23  2023-04-24  2023-04-25  \n",
       "15885           0           0           0  \n",
       "15886           0           0           0  \n",
       "15887           0           0           0  \n",
       "15888           0           0           0  \n",
       "15889           0           0           0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "12fe6034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>대분류</th>\n",
       "      <th>중분류</th>\n",
       "      <th>소분류</th>\n",
       "      <th>브랜드</th>\n",
       "      <th>날짜</th>\n",
       "      <th>판매량</th>\n",
       "      <th>검색수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7293480</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293481</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293482</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293483</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293484</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293485</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293486</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293487</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293488</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293489</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293490</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293491</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293492</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293493</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293494</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293495</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293496</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293497</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293498</th>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0009</td>\n",
       "      <td>B002-C003-0049</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293499</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293500</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293501</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293502</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293503</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03798</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293504</th>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0002</td>\n",
       "      <td>B002-C003-0010</td>\n",
       "      <td>B002-03799</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293505</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0042</td>\n",
       "      <td>B002-03799</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293506</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03799</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293507</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03799</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293508</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-03799</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293509</th>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0004</td>\n",
       "      <td>B002-C003-0020</td>\n",
       "      <td>B002-03799</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    대분류             중분류             소분류         브랜드  \\\n",
       "7293480  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293481  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293482  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293483  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293484  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293485  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293486  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293487  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293488  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293489  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293490  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293491  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293492  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293493  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293494  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293495  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293496  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293497  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293498  B002-C001-0002  B002-C002-0009  B002-C003-0049  B002-03798   \n",
       "7293499  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293500  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293501  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293502  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293503  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03798   \n",
       "7293504  B002-C001-0002  B002-C002-0002  B002-C003-0010  B002-03799   \n",
       "7293505  B002-C001-0003  B002-C002-0008  B002-C003-0042  B002-03799   \n",
       "7293506  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03799   \n",
       "7293507  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03799   \n",
       "7293508  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-03799   \n",
       "7293509  B002-C001-0002  B002-C002-0004  B002-C003-0020  B002-03799   \n",
       "\n",
       "                날짜       판매량       검색수  \n",
       "7293480 2023-04-04  0.000010  0.000008  \n",
       "7293481 2023-04-04  0.000000  0.000008  \n",
       "7293482 2023-04-04  0.000000  0.000008  \n",
       "7293483 2023-04-04  0.000000  0.000008  \n",
       "7293484 2023-04-04  0.000000  0.000008  \n",
       "7293485 2023-04-04  0.000000  0.000008  \n",
       "7293486 2023-04-04  0.000000  0.000008  \n",
       "7293487 2023-04-04  0.000000  0.000008  \n",
       "7293488 2023-04-04  0.000000  0.000008  \n",
       "7293489 2023-04-04  0.000000  0.000008  \n",
       "7293490 2023-04-04  0.000000  0.000008  \n",
       "7293491 2023-04-04  0.000000  0.000008  \n",
       "7293492 2023-04-04  0.000000  0.000008  \n",
       "7293493 2023-04-04  0.000000  0.000008  \n",
       "7293494 2023-04-04  0.000000  0.000008  \n",
       "7293495 2023-04-04  0.000000  0.000008  \n",
       "7293496 2023-04-04  0.000000  0.000008  \n",
       "7293497 2023-04-04  0.000005  0.000008  \n",
       "7293498 2023-04-04  0.000000  0.000008  \n",
       "7293499 2023-04-04  0.000110  0.000008  \n",
       "7293500 2023-04-04  0.000025  0.000008  \n",
       "7293501 2023-04-04  0.000005  0.000008  \n",
       "7293502 2023-04-04  0.000000  0.000008  \n",
       "7293503 2023-04-04  0.000000  0.000008  \n",
       "7293504 2023-04-04  0.000000  0.000379  \n",
       "7293505 2023-04-04  0.000000  0.000379  \n",
       "7293506 2023-04-04  0.000015  0.000379  \n",
       "7293507 2023-04-04  0.000000  0.000379  \n",
       "7293508 2023-04-04  0.000010  0.000379  \n",
       "7293509 2023-04-04  0.000000  0.000379  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "7c83c51b-f979-4930-9372-f03bdb33abc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = ['대분류', '중분류', '소분류','브랜드'] # '대분류', '중분류', '소분류',\n",
    "\n",
    "for col in categorical_columns:\n",
    "    label_encoder.fit(result_df[col])\n",
    "    result_df[col] = label_encoder.transform(result_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "16768f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>대분류</th>\n",
       "      <th>중분류</th>\n",
       "      <th>소분류</th>\n",
       "      <th>브랜드</th>\n",
       "      <th>날짜</th>\n",
       "      <th>판매량</th>\n",
       "      <th>검색수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   대분류  중분류  소분류  브랜드         날짜  판매량       검색수\n",
       "0    1    6   37    0 2022-01-01  0.0  0.000063\n",
       "1    2    7   43    1 2022-01-01  0.0  0.000945\n",
       "2    2    7   43    1 2022-01-01  0.0  0.000945\n",
       "3    2    7   43    1 2022-01-01  0.0  0.000945\n",
       "4    0    0    2    2 2022-01-01  0.0  0.000025"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "8bbb36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 테스트 데이터로 분할\n",
    "train_size = int(0.8 * len(result_df))\n",
    "train_data = result_df[:train_size]\n",
    "test_data = result_df[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "1170da74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0006932690886170807\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 결측값을 0으로 대체하는 Imputer 생성\n",
    "imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "\n",
    "# 피처와 타겟 분리\n",
    "X_train = train_data[['대분류', '중분류', '소분류', '브랜드', '검색수']]\n",
    "y_train = train_data['판매량']\n",
    "\n",
    "# 결측값 대체\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "\n",
    "# 선형 회귀 모델 생성 및 학습\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_imputed, y_train)\n",
    "\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "X_test = test_data[['대분류', '중분류', '소분류', '브랜드', '검색수']]\n",
    "y_test = test_data['판매량']\n",
    "\n",
    "# 결측값 대체\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(X_test_imputed)\n",
    "\n",
    "# 평균 제곱근 오차 계산\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "print(f\"RMSE: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d509f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "a331a981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>2023-04-05</th>\n",
       "      <th>2023-04-06</th>\n",
       "      <th>2023-04-07</th>\n",
       "      <th>2023-04-08</th>\n",
       "      <th>2023-04-09</th>\n",
       "      <th>2023-04-10</th>\n",
       "      <th>2023-04-11</th>\n",
       "      <th>2023-04-12</th>\n",
       "      <th>2023-04-13</th>\n",
       "      <th>...</th>\n",
       "      <th>2023-04-16</th>\n",
       "      <th>2023-04-17</th>\n",
       "      <th>2023-04-18</th>\n",
       "      <th>2023-04-19</th>\n",
       "      <th>2023-04-20</th>\n",
       "      <th>2023-04-21</th>\n",
       "      <th>2023-04-22</th>\n",
       "      <th>2023-04-23</th>\n",
       "      <th>2023-04-24</th>\n",
       "      <th>2023-04-25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15885</th>\n",
       "      <td>15885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15886</th>\n",
       "      <td>15886</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15887</th>\n",
       "      <td>15887</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15888</th>\n",
       "      <td>15888</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15889</th>\n",
       "      <td>15889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  2023-04-05  2023-04-06  2023-04-07  2023-04-08  2023-04-09  \\\n",
       "15885  15885           0           0           0           0           0   \n",
       "15886  15886           0           0           0           0           0   \n",
       "15887  15887           0           0           0           0           0   \n",
       "15888  15888           0           0           0           0           0   \n",
       "15889  15889           0           0           0           0           0   \n",
       "\n",
       "       2023-04-10  2023-04-11  2023-04-12  2023-04-13  ...  2023-04-16  \\\n",
       "15885           0           0           0           0  ...           0   \n",
       "15886           0           0           0           0  ...           0   \n",
       "15887           0           0           0           0  ...           0   \n",
       "15888           0           0           0           0  ...           0   \n",
       "15889           0           0           0           0  ...           0   \n",
       "\n",
       "       2023-04-17  2023-04-18  2023-04-19  2023-04-20  2023-04-21  2023-04-22  \\\n",
       "15885           0           0           0           0           0           0   \n",
       "15886           0           0           0           0           0           0   \n",
       "15887           0           0           0           0           0           0   \n",
       "15888           0           0           0           0           0           0   \n",
       "15889           0           0           0           0           0           0   \n",
       "\n",
       "       2023-04-23  2023-04-24  2023-04-25  \n",
       "15885           0           0           0  \n",
       "15886           0           0           0  \n",
       "15887           0           0           0  \n",
       "15888           0           0           0  \n",
       "15889           0           0           0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('E:/LG/LG_data/sample_submission.csv')\n",
    "submit.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "fb39c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 첫 번째 CSV 파일 불러오기\n",
    "csv_file_path1 = 'E:/LG/LG_data/sample_submission.csv'\n",
    "train_data = pd.read_csv(csv_file_path1)\n",
    "\n",
    "# '날짜' 열을 행으로 변환\n",
    "df_meltedsss = pd.melt(train_data, id_vars=['ID'], var_name='날짜', value_name='판매량')\n",
    "\n",
    "# '날짜' 열의 데이터를 날짜형으로 변환\n",
    "df_meltedsss['날짜'] = pd.to_datetime(df_melted['날짜'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "af9df713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>날짜</th>\n",
       "      <th>판매량</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID         날짜  판매량\n",
       "0   0 2022-01-01    0\n",
       "1   1 2022-01-01    0\n",
       "2   2 2022-01-01    0\n",
       "3   3 2022-01-01    0\n",
       "4   4 2022-01-01    0"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meltedsss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "c7eb61ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (1458702) does not match length of index (15890)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[238], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m submit[\u001b[39m'\u001b[39;49m\u001b[39m판매량\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m y_pred\n\u001b[0;32m      2\u001b[0m submit\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3950\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3947\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3948\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3949\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[1;32m-> 3950\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4143\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4134\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4135\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4136\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4141\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4142\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4143\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[0;32m   4145\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   4146\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m   4147\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   4148\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   4149\u001b[0m     ):\n\u001b[0;32m   4150\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4151\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4870\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4867\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[0;32m   4869\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4870\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[0;32m   4871\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\common.py:576\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[1;32m--> 576\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    577\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    579\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (1458702) does not match length of index (15890)"
     ]
    }
   ],
   "source": [
    "submit['판매량'] = y_pred\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5186ccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submit.to_csv('E:/LG/LG_data/models/baseline_submit_epoch_30_90_4096_512_RAdam_GRU_02_LAYER_33333.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c439f758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacac628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc7045a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2abe1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "949d57ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[131], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m submit\u001b[39m.\u001b[39;49miloc[:,\u001b[39m1\u001b[39;49m:] \u001b[39m=\u001b[39m y_pred\n\u001b[0;32m      2\u001b[0m submit\u001b[39m.\u001b[39mtail()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:849\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    846\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    848\u001b[0m iloc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39miloc\n\u001b[1;32m--> 849\u001b[0m iloc\u001b[39m.\u001b[39;49m_setitem_with_indexer(indexer, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1835\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1832\u001b[0m \u001b[39m# align and set the values\u001b[39;00m\n\u001b[0;32m   1833\u001b[0m \u001b[39mif\u001b[39;00m take_split_path:\n\u001b[0;32m   1834\u001b[0m     \u001b[39m# We have to operate column-wise\u001b[39;00m\n\u001b[1;32m-> 1835\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_with_indexer_split_path(indexer, value, name)\n\u001b[0;32m   1836\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1837\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1920\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1917\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_single_column(ilocs[\u001b[39m0\u001b[39m], value, pi)\n\u001b[0;32m   1919\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1920\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1921\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMust have equal len keys and value \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1922\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mwhen setting with an iterable\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1923\u001b[0m         )\n\u001b[0;32m   1925\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1926\u001b[0m     \u001b[39m# scalar value\u001b[39;00m\n\u001b[0;32m   1927\u001b[0m     \u001b[39mfor\u001b[39;00m loc \u001b[39min\u001b[39;00m ilocs:\n",
      "\u001b[1;31mValueError\u001b[0m: Must have equal len keys and value when setting with an iterable"
     ]
    }
   ],
   "source": [
    "submit.iloc[:,1:] = y_pred\n",
    "submit.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8b6ef9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>대분류</th>\n",
       "      <th>중분류</th>\n",
       "      <th>소분류</th>\n",
       "      <th>브랜드</th>\n",
       "      <th>날짜</th>\n",
       "      <th>판매량</th>\n",
       "      <th>검색수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7293505</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>3169</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293506</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>3169</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293507</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>3169</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293508</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>3169</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293509</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>3169</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         대분류  중분류  소분류   브랜드         날짜       판매량       검색수\n",
       "7293505    2    7   41  3169 2023-04-04  0.000000  0.000379\n",
       "7293506    2    7   43  3169 2023-04-04  0.000015  0.000379\n",
       "7293507    2    7   43  3169 2023-04-04  0.000000  0.000379\n",
       "7293508    2    7   43  3169 2023-04-04  0.000010  0.000379\n",
       "7293509    1    3   19  3169 2023-04-04  0.000000  0.000379"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3c203f18-dfe9-430a-8082-f1143267b296",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 120 and the array at index 1 has size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[119], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_input, train_target \u001b[39m=\u001b[39m make_result_data(result_df)\n\u001b[0;32m      2\u001b[0m test_input \u001b[39m=\u001b[39m make_predict_data(result_df)\n",
      "Cell \u001b[1;32mIn[117], line 24\u001b[0m, in \u001b[0;36mmake_result_data\u001b[1;34m(data, train_size, predict_size, batch_size)\u001b[0m\n\u001b[0;32m     21\u001b[0m sales_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(data\u001b[39m.\u001b[39miloc[idx, \u001b[39m5\u001b[39m:])\n\u001b[0;32m     23\u001b[0m window \u001b[39m=\u001b[39m sales_data[j : j \u001b[39m+\u001b[39m window_size]\n\u001b[1;32m---> 24\u001b[0m temp_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mcolumn_stack((np\u001b[39m.\u001b[39;49mtile(encode_info, (train_size, \u001b[39m1\u001b[39;49m)), window[:train_size]))\n\u001b[0;32m     25\u001b[0m input_batch\u001b[39m.\u001b[39mappend(temp_data)\n\u001b[0;32m     26\u001b[0m target_batch\u001b[39m.\u001b[39mappend(window[train_size:])\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mcolumn_stack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\shape_base.py:656\u001b[0m, in \u001b[0;36mcolumn_stack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    654\u001b[0m         arr \u001b[39m=\u001b[39m array(arr, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, subok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, ndmin\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mT\n\u001b[0;32m    655\u001b[0m     arrays\u001b[39m.\u001b[39mappend(arr)\n\u001b[1;32m--> 656\u001b[0m \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(arrays, \u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 120 and the array at index 1 has size 2"
     ]
    }
   ],
   "source": [
    "train_input, train_target = make_result_data(result_df)\n",
    "test_input = make_predict_data(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3c710abd-1be0-4926-803f-c732d7bffdb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[118], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_len \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_input)\n\u001b[0;32m      2\u001b[0m val_ratio \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m\n\u001b[0;32m      3\u001b[0m test_ratio \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_input' is not defined"
     ]
    }
   ],
   "source": [
    "data_len = len(train_input)\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "\n",
    "val_len = int(data_len * val_ratio)\n",
    "test_len = int(data_len * test_ratio)\n",
    "\n",
    "val_input = train_input[-val_len:]\n",
    "val_target = train_target[-val_len:]\n",
    "\n",
    "\n",
    "train_input = train_input[:-val_len - test_len]\n",
    "train_target = train_target[:-val_len - test_len]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3be176ad-ccc8-425c-9627-f583c0647489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4105976, 120, 5),\n",
       " (4105976, 21),\n",
       " (513247, 120, 5),\n",
       " (513247, 21),\n",
       " (15890, 120, 5))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape, train_target.shape, val_input.shape, val_target.shape, test_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2f3d76-fcf4-4866-a578-6bb76783bbed",
   "metadata": {},
   "source": [
    "### Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ec0a970-4d99-486d-b9b5-210f3cdca353",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.Y is not None:\n",
    "            return torch.Tensor(self.X[index]), torch.Tensor(self.Y[index])\n",
    "        return torch.Tensor(self.X[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3614347b-da14-466f-9d04-b81e5448a9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_input, train_target)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = CustomDataset(val_input, val_target)\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63f0b66-817d-49ff-9163-a975fb0f239d",
   "metadata": {},
   "source": [
    "### 모델 선언"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac10a87",
   "metadata": {},
   "source": [
    "## GRU 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fdc897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# import torch\n",
    "\n",
    "# class BaseModel(nn.Module):\n",
    "#     def __init__(self, input_size=5, hidden_size=512, num_layers=2, output_size=CFG['PREDICT_SIZE']):\n",
    "#         super(BaseModel, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_layers = num_layers\n",
    "#         self.gru = nn.GRU(input_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(hidden_size, hidden_size // 2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(hidden_size // 2, output_size)\n",
    "#         )\n",
    "\n",
    "#         self.actv = nn.ReLU()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # x shape: (B, TRAIN_WINDOW_SIZE, 5)\n",
    "#         batch_size = x.size(0)\n",
    "#         hidden = self.init_hidden(batch_size, x.device)\n",
    "\n",
    "#         # GRU layer\n",
    "#         gru_out, hidden = self.gru(x, hidden)\n",
    "\n",
    "#         # Only use the last output sequencea\n",
    "#         last_output = gru_out[:, -1, :]\n",
    "\n",
    "#         # Fully connected layer\n",
    "#         output = self.actv(self.fc(last_output))\n",
    "\n",
    "#         return output.squeeze(1)\n",
    "\n",
    "#     def init_hidden(self, batch_size, device):\n",
    "#         # Initialize hidden state for all GRU layers\n",
    "#         return torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1991cb6",
   "metadata": {},
   "source": [
    "## 개선된 gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "faa4f6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedModel(nn.Module):\n",
    "    def __init__(self, input_size=5, hidden_size=512, num_layers=2, output_size=CFG['PREDICT_SIZE'], dropout_prob=0.2):\n",
    "        super(ImprovedModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.ln = nn.LayerNorm(hidden_size)  # Layer Normalization\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size // 2, output_size)\n",
    "        )\n",
    "        self.actv = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        hidden = self.init_hidden(batch_size, x.device)\n",
    "\n",
    "        gru_out, hidden = self.gru(x, hidden)\n",
    "        gru_out = self.dropout(gru_out)\n",
    "        gru_out = self.ln(gru_out)  # Applying Layer Normalization\n",
    "\n",
    "        last_output = gru_out[:, -1, :]\n",
    "\n",
    "        output = self.actv(self.fc(last_output))\n",
    "\n",
    "        return output.squeeze(1)\n",
    "    def init_hidden(self, batch_size, device):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f932328",
   "metadata": {},
   "source": [
    "## lstm으로 만든것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77047f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# import torch\n",
    "\n",
    "# class ImprovedModel(nn.Module):\n",
    "#     def __init__(self, input_size=5, hidden_size=512, num_layers=2, output_size=CFG['PREDICT_SIZE']):\n",
    "#         super(ImprovedModel, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_layers = num_layers\n",
    "#         self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True)  # Using nn.LSTM instead of nn.GRU\n",
    "#         self.dropout = nn.Dropout(0.5)  # Adding dropout after LSTM\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(hidden_size, hidden_size // 2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(hidden_size // 2, output_size)\n",
    "#         )\n",
    "#         self.actv = nn.ReLU()  # Using LeakyReLU activation\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         batch_size = x.size(0)\n",
    "#         hidden, cell = self.init_hidden(batch_size, x.device)  # Initializing hidden and cell states for LSTM\n",
    "\n",
    "#         lstm_out, (hidden, cell) = self.lstm(x, (hidden, cell))  # Using LSTM instead of GRU\n",
    "#         lstm_out = self.dropout(lstm_out)  # Applying dropout\n",
    "\n",
    "#         last_output = lstm_out[:, -1, :]\n",
    "\n",
    "#         output = self.actv(self.fc(last_output))\n",
    "\n",
    "#         return output.squeeze(1)\n",
    "\n",
    "#     def init_hidden(self, batch_size, device):\n",
    "#         return (torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device),\n",
    "#                 torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device))  # Initializing hidden and cell states for LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec560118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    best_loss = 9999999\n",
    "    best_model = None\n",
    "    \n",
    "    \n",
    "    \n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        train_mae = []\n",
    "        \n",
    "        for X, Y in tqdm(iter(train_loader)):\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(X)\n",
    "            loss = criterion(output, Y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "        \n",
    "        val_loss = validation(model, val_loader, criterion, device)\n",
    "        print(f'Epoch : [{epoch}] Train Loss : [{np.mean(train_loss):.5f}] Val Loss : [{val_loss:.5f}]')\n",
    "        \n",
    "\n",
    "        # # 학습 루프 안에서\n",
    "        # if best_loss > val_loss:\n",
    "        #     best_loss = val_loss\n",
    "        #     best_model = model\n",
    "        #     print('Model Saved')\n",
    "\n",
    "        # 학습이 끝난 후\n",
    "    return model  # 모든 모델을 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bbe1802a-35ff-4b43-a1a8-16c8079baf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, Y in tqdm(iter(val_loader)):\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            \n",
    "            output = model(X)\n",
    "            loss = criterion(output, Y)\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "    return np.mean(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c83fa73-30d5-489c-852b-d655f76a200c",
   "metadata": {},
   "source": [
    "## Run !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1570b00-a309-4e5e-b53d-5848ba53eb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1003/1003 [08:55<00:00,  1.87it/s]\n",
      "100%|██████████| 126/126 [00:31<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1] Train Loss : [0.01697] Val Loss : [0.01657]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1003/1003 [09:07<00:00,  1.83it/s]\n",
      "100%|██████████| 126/126 [00:33<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2] Train Loss : [0.01547] Val Loss : [0.01701]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1003/1003 [09:13<00:00,  1.81it/s]\n",
      "100%|██████████| 126/126 [00:33<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3] Train Loss : [0.01531] Val Loss : [0.01656]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1003/1003 [08:33<00:00,  1.95it/s]\n",
      "100%|██████████| 126/126 [00:27<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4] Train Loss : [0.01553] Val Loss : [0.01655]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1003/1003 [08:23<00:00,  1.99it/s]\n",
      " 33%|███▎      | 41/126 [00:10<00:20,  4.11it/s]"
     ]
    }
   ],
   "source": [
    "model = ImprovedModel() # BaseModel() \n",
    "optimizer = torch.optim.RAdam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b20af7-f5b1-4a7a-8eb9-7dde5bbf3d04",
   "metadata": {},
   "source": [
    "## 모델 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01d7ca0-899e-4515-a43e-890549f8f3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test_input, None)\n",
    "test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214f30d4-2b19-479f-89b7-bf5bb2adc111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X in tqdm(iter(test_loader)):\n",
    "            X = X.to(device)\n",
    "            \n",
    "            output = model(X)\n",
    "            \n",
    "            # 모델 출력인 output을 CPU로 이동하고 numpy 배열로 변환\n",
    "            output = output.cpu().numpy()\n",
    "            \n",
    "            predictions.extend(output)\n",
    "    \n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b76e053-6fd2-44a7-8631-d903e7ffa292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# pred = inference(infer_model, test_loader, device)\n",
    "pred = inference(infer_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517978aa-445a-4ece-9217-432682f71230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 결과를 inverse scaling\n",
    "for idx in range(len(pred)):\n",
    "    pred[idx, :] = pred[idx, :]  * (scale_max_dict[idx] - scale_min_dict[idx]) + scale_min_dict[idx]\n",
    "    \n",
    "# 결과 후처리\n",
    "pred = np.round(pred, 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90fa77e-fd03-4539-98fe-563fe2a25121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15890, 21)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48b50eb-d2d8-4c2d-a5e7-9607220fd794",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78c84bb-5dbe-4fb3-aff0-7e229ae29a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>2023-04-05</th>\n",
       "      <th>2023-04-06</th>\n",
       "      <th>2023-04-07</th>\n",
       "      <th>2023-04-08</th>\n",
       "      <th>2023-04-09</th>\n",
       "      <th>2023-04-10</th>\n",
       "      <th>2023-04-11</th>\n",
       "      <th>2023-04-12</th>\n",
       "      <th>2023-04-13</th>\n",
       "      <th>...</th>\n",
       "      <th>2023-04-16</th>\n",
       "      <th>2023-04-17</th>\n",
       "      <th>2023-04-18</th>\n",
       "      <th>2023-04-19</th>\n",
       "      <th>2023-04-20</th>\n",
       "      <th>2023-04-21</th>\n",
       "      <th>2023-04-22</th>\n",
       "      <th>2023-04-23</th>\n",
       "      <th>2023-04-24</th>\n",
       "      <th>2023-04-25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15885</th>\n",
       "      <td>15885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15886</th>\n",
       "      <td>15886</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15887</th>\n",
       "      <td>15887</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15888</th>\n",
       "      <td>15888</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15889</th>\n",
       "      <td>15889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  2023-04-05  2023-04-06  2023-04-07  2023-04-08  2023-04-09  \\\n",
       "15885  15885           0           0           0           0           0   \n",
       "15886  15886           0           0           0           0           0   \n",
       "15887  15887           0           0           0           0           0   \n",
       "15888  15888           0           0           0           0           0   \n",
       "15889  15889           0           0           0           0           0   \n",
       "\n",
       "       2023-04-10  2023-04-11  2023-04-12  2023-04-13  ...  2023-04-16  \\\n",
       "15885           0           0           0           0  ...           0   \n",
       "15886           0           0           0           0  ...           0   \n",
       "15887           0           0           0           0  ...           0   \n",
       "15888           0           0           0           0  ...           0   \n",
       "15889           0           0           0           0  ...           0   \n",
       "\n",
       "       2023-04-17  2023-04-18  2023-04-19  2023-04-20  2023-04-21  2023-04-22  \\\n",
       "15885           0           0           0           0           0           0   \n",
       "15886           0           0           0           0           0           0   \n",
       "15887           0           0           0           0           0           0   \n",
       "15888           0           0           0           0           0           0   \n",
       "15889           0           0           0           0           0           0   \n",
       "\n",
       "       2023-04-23  2023-04-24  2023-04-25  \n",
       "15885           0           0           0  \n",
       "15886           0           0           0  \n",
       "15887           0           0           0  \n",
       "15888           0           0           0  \n",
       "15889           0           0           0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('E:/LG/LG_data/sample_submission.csv')\n",
    "submit.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db62d9c-b3ad-440a-8cc7-4897b2e4860f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>2023-04-05</th>\n",
       "      <th>2023-04-06</th>\n",
       "      <th>2023-04-07</th>\n",
       "      <th>2023-04-08</th>\n",
       "      <th>2023-04-09</th>\n",
       "      <th>2023-04-10</th>\n",
       "      <th>2023-04-11</th>\n",
       "      <th>2023-04-12</th>\n",
       "      <th>2023-04-13</th>\n",
       "      <th>...</th>\n",
       "      <th>2023-04-16</th>\n",
       "      <th>2023-04-17</th>\n",
       "      <th>2023-04-18</th>\n",
       "      <th>2023-04-19</th>\n",
       "      <th>2023-04-20</th>\n",
       "      <th>2023-04-21</th>\n",
       "      <th>2023-04-22</th>\n",
       "      <th>2023-04-23</th>\n",
       "      <th>2023-04-24</th>\n",
       "      <th>2023-04-25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15885</th>\n",
       "      <td>15885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15886</th>\n",
       "      <td>15886</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15887</th>\n",
       "      <td>15887</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15888</th>\n",
       "      <td>15888</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15889</th>\n",
       "      <td>15889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  2023-04-05  2023-04-06  2023-04-07  2023-04-08  2023-04-09  \\\n",
       "15885  15885           0           0           0           0           0   \n",
       "15886  15886           0           0           0           0           0   \n",
       "15887  15887           0           0           0           0           0   \n",
       "15888  15888           0           0           0           0           0   \n",
       "15889  15889           0           0           0           0           0   \n",
       "\n",
       "       2023-04-10  2023-04-11  2023-04-12  2023-04-13  ...  2023-04-16  \\\n",
       "15885           0           0           0           0  ...           0   \n",
       "15886           0           0           0           0  ...           0   \n",
       "15887           0           0           0           0  ...           0   \n",
       "15888           0           0           0           0  ...           0   \n",
       "15889           0           0           0           0  ...           0   \n",
       "\n",
       "       2023-04-17  2023-04-18  2023-04-19  2023-04-20  2023-04-21  2023-04-22  \\\n",
       "15885           0           1           0           0           0           0   \n",
       "15886           0           1           0           0           0           0   \n",
       "15887           0           1           0           0           0           0   \n",
       "15888           0           1           0           0           0           0   \n",
       "15889           0           1           0           0           0           0   \n",
       "\n",
       "       2023-04-23  2023-04-24  2023-04-25  \n",
       "15885           0           0           0  \n",
       "15886           0           0           0  \n",
       "15887           0           0           0  \n",
       "15888           0           0           0  \n",
       "15889           0           0           0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.iloc[:,1:] = pred\n",
    "submit.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4142f749-f20f-4797-b586-581e5c778297",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('E:/LG/LG_data/models/baseline_submit_epoch_30_90_4096_512_RAdam_GRU_02_LAYER_33333.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f8b272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98b1934",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.14 (NGC 22.12/Python 3.8) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
